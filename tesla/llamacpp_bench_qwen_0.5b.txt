load_backend: loaded RPC backend from /home/arameshranganathan/llama_cpp/build/bin/libggml-rpc.so
ggml_vulkan: Found 1 Vulkan devices:
ggml_vulkan: 0 = Tesla T4 (NVIDIA) | uma: 0 | fp16: 1 | bf16: 1 | warp size: 32 | shared memory: 49152 | int dot: 1 | matrix cores: NV_coopmat2
load_backend: loaded Vulkan backend from /home/arameshranganathan/llama_cpp/build/bin/libggml-vulkan.so
load_backend: loaded CPU backend from /home/arameshranganathan/llama_cpp/build/bin/libggml-cpu-haswell.so
| model                          |       size |     params | backend    | ngl |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | --------------: | -------------------: |
| qwen2 1B Q4_K - Medium         | 373.71 MiB |   494.03 M | Vulkan     |  99 |           pp512 |     6739.95 ± 580.89 |
| qwen2 1B Q4_K - Medium         | 373.71 MiB |   494.03 M | Vulkan     |  99 |           tg128 |        254.50 ± 0.52 |

build: 21d31e081 (7122)
