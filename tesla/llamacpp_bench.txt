load_backend: loaded RPC backend from /home/arameshranganathan/llama_cpp/build/bin/libggml-rpc.so
ggml_vulkan: Found 1 Vulkan devices:
ggml_vulkan: 0 = Tesla T4 (NVIDIA) | uma: 0 | fp16: 1 | bf16: 1 | warp size: 32 | shared memory: 49152 | int dot: 1 | matrix cores: NV_coopmat2
load_backend: loaded Vulkan backend from /home/arameshranganathan/llama_cpp/build/bin/libggml-vulkan.so
load_backend: loaded CPU backend from /home/arameshranganathan/llama_cpp/build/bin/libggml-cpu-haswell.so
| model                          |       size |     params | backend    | ngl |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | --------------: | -------------------: |
| gemma3 1B Q4_K - Medium        | 762.49 MiB |   999.89 M | Vulkan     |  99 |           pp512 |    6287.85 ± 1259.79 |
| gemma3 1B Q4_K - Medium        | 762.49 MiB |   999.89 M | Vulkan     |  99 |           tg128 |        147.38 ± 0.39 |

build: 21d31e081 (7122)
